Saving to path /home/yamanishi/project/trip_recommend/data/analyzer/probe.pth
Enabling layer 2
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.7186, 1.8316, 1.5607,  ..., 1.8020, 1.5964, 1.6861], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([0., 1., 1.,  ..., 1., 1., 0.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.15196075380897558
attention True
attention False
attention True
attention False
attention True
attention True
epoch 0 loss tensor(0.1621, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.7350, device='cuda:3', grad_fn=<AddBackward0>)
tensor(0.5500, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
attention True
attention False
attention True
attention False
attention True
attention True
original score: 0.7252716597689418 gated_score: 0.7252716658466781
Found better probe with sparsity=1.0000. Keeping these parameters.
Saving to path /home/yamanishi/project/trip_recommend/data/analyzer/probe.pth
Loading from path /home/yamanishi/project/trip_recommend/data/analyzer/probe.pth
epoch 0 percent_div -8.379944579885128e-09 sparsity 1.0
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([1., 1., 1.,  ..., 0., 1., 0.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 0., 0.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.15125652115290872
attention True
attention False
attention True
attention False
attention True
attention True
epoch 1 loss tensor(0.1663, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.6401, device='cuda:3', grad_fn=<AddBackward0>)
tensor(0.6505, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([0.2129, 0.0736, 0.0040,  ..., 0.0643, 0.0161, 0.0345], device='cuda:3',
       grad_fn=<AddBackward0>)
attention True
attention False
attention True
attention False
attention True
attention True
original score: 0.7252716658110289 gated_score: 0.6412743759791183
Loading from path /home/yamanishi/project/trip_recommend/data/analyzer/probe.pth
epoch 1 percent_div 0.11581493361936498 sparsity 0.7191241979598999
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([1., 0., 0.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 0.,  ..., 0., 0., 1.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.15223145295954033
attention True
attention False
attention True
attention False
attention True
attention True
epoch 2 loss tensor(0.1681, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.6401, device='cuda:3', grad_fn=<AddBackward0>)
tensor(0.7244, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([ 0.1857,  0.0424, -0.0219,  ...,  0.0324, -0.0148,  0.0041],
       device='cuda:3', grad_fn=<AddBackward0>)
attention True
attention False
attention True
attention False
attention True
attention True
original score: 0.7252716619380056 gated_score: 0.6374982430438295
Loading from path /home/yamanishi/project/trip_recommend/data/analyzer/probe.pth
epoch 2 percent_div 0.12102143720828122 sparsity 0.7097342610359192
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 0., 0., 1.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.15137009033676635
attention True
attention False
attention True
attention False
attention True
attention True
epoch 3 loss tensor(0.1669, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.6401, device='cuda:3', grad_fn=<AddBackward0>)
tensor(0.7861, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([ 0.1721,  0.0265, -0.0353,  ...,  0.0160, -0.0303, -0.0114],
       device='cuda:3', grad_fn=<AddBackward0>)
attention True
attention False
attention True
attention False
attention True
attention True
original score: 0.725271666021571 gated_score: 0.6346991768438195
Loading from path /home/yamanishi/project/trip_recommend/data/analyzer/probe.pth
epoch 3 percent_div 0.12488077698468605 sparsity 0.7056997418403625
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([1., 1., 1.,  ..., 0., 0., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 1., 1., 0.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.15196490245496125
attention True
attention False
attention True
attention False
attention True
attention True
epoch 4 loss tensor(0.1675, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.6401, device='cuda:3', grad_fn=<AddBackward0>)
tensor(0.8396, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([ 0.1640,  0.0168, -0.0434,  ...,  0.0060, -0.0394, -0.0205],
       device='cuda:3', grad_fn=<AddBackward0>)
attention True
attention False
attention True
attention False
attention True
attention True
original score: 0.7252716658717832 gated_score: 0.633481787078989
epoch 4 percent_div 0.12655930613594554 sparsity 0.7034542560577393
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True
True tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([1., 0., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([0., 0., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 0., 1.,  ..., 1., 1., 0.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.1522423431552527
attention True
attention False
attention True
attention False
attention True
attention True
epoch 5 loss tensor(0.1680, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.6401, device='cuda:3', grad_fn=<AddBackward0>)
tensor(0.8883, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([ 0.1589,  0.0108, -0.0484,  ..., -0.0005, -0.0453, -0.0265],
       device='cuda:3', grad_fn=<AddBackward0>)
attention True
attention False
attention True
attention False
attention True
attention True
original score: 0.7252716615163474 gated_score: 0.632843459043203
Loading from path /home/yamanishi/project/trip_recommend/data/analyzer/probe.pth
epoch 5 percent_div 0.1274394235670285 sparsity 0.7020577192306519
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 0., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.15162575064563302
attention True
attention False
attention True
attention False
attention True
attention True
epoch 6 loss tensor(0.1666, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.6401, device='cuda:3', grad_fn=<AddBackward0>)
tensor(0.9333, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([ 0.1554,  0.0066, -0.0520,  ..., -0.0050, -0.0493, -0.0306],
       device='cuda:3', grad_fn=<AddBackward0>)
attention True
attention False
attention True
attention False
attention True
attention True
original score: 0.7252716666470715 gated_score: 0.6323927155573955
Loading from path /home/yamanishi/project/trip_recommend/data/analyzer/probe.pth
epoch 6 percent_div 0.12806091201529368 sparsity 0.701119601726532
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([0., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.15190007986143522
attention True
attention False
attention True
attention False
attention True
attention True
epoch 7 loss tensor(0.1674, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.6401, device='cuda:3', grad_fn=<AddBackward0>)
tensor(0.9750, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([ 0.1528,  0.0034, -0.0546,  ..., -0.0082, -0.0522, -0.0337],
       device='cuda:3', grad_fn=<AddBackward0>)
attention True
attention False
attention True
attention False
attention True
attention True
original score: 0.7252716627197394 gated_score: 0.6319582413435104
epoch 7 percent_div 0.12865995760306895 sparsity 0.7004926800727844
True tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
True
True tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
True tensor([0.9398, 0.9430, 0.7494,  ..., 0.8738, 0.7861, 0.8171], device='cuda:3',
       grad_fn=<AddBackward0>)
compute graph mask loss {'word__revrelate__spot': [tensor([1., 0., 1.,  ..., 1., 0., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>), tensor([1., 1., 0.,  ..., 1., 1., 1.], device='cuda:3', grad_fn=<AddBackward0>)]}
sparsity 0.15220033811464784
attention True
attention False
attention True
attention False
attention True
attention True
epoch 8 loss tensor(0.1671, device='cuda:3', grad_fn=<DivBackward0>) penalty tensor(2.6401, device='cuda:3', grad_fn=<AddBackward0>)
tensor(1.0146, device='cuda:3', requires_grad=True)
False tensor([1.6014, 1.5873, 1.4671,  ..., 2.0290, 1.6276, 1.7680], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([1.8977, 1.9729, 2.0944,  ..., 1.6850, 2.0773, 1.7723], device='cuda:3',
       grad_fn=<AddBackward0>)
False tensor([ 0.1510,  0.0010, -0.0566,  ..., -0.0104, -0.0542, -0.0359],
