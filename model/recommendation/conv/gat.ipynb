{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import LSTM\n",
    "\n",
    "from torch_geometric.nn.aggr import Aggregation\n",
    "\n",
    "\n",
    "class LSTMAggregation(Aggregation):\n",
    "    r\"\"\"Performs LSTM-style aggregation in which the elements to aggregate are\n",
    "    interpreted as a sequence, as described in the `\"Inductive Representation\n",
    "    Learning on Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper.\n",
    "\n",
    "    .. warning::\n",
    "        :class:`LSTMAggregation` is not a permutation-invariant operator.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        **kwargs (optional): Additional arguments of :class:`torch.nn.LSTM`.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, **kwargs):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.lstm = LSTM(in_channels, out_channels, batch_first=True, **kwargs)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lstm.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, index: Optional[Tensor] = None,\n",
    "                ptr: Optional[Tensor] = None, dim_size: Optional[int] = None,\n",
    "                dim: int = -2) -> Tensor:\n",
    "        x, _ = self.to_dense_batch(x, index, ptr, dim_size, dim)\n",
    "        return self.lstm(x)[0][:, -1]\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4817e-02, 1.3328e-04, 3.1582e-01, 2.1440e-01],\n",
      "        [9.7630e-02, 3.3602e-01, 6.9767e-01, 2.0946e-01],\n",
      "        [3.8457e-01, 7.2020e-01, 1.1124e-01, 9.1535e-01]]) tensor([3, 9, 6])\n",
      "tensor([0, 2, 1])\n",
      "tensor([[1.4817e-02, 1.3328e-04, 3.1582e-01, 2.1440e-01],\n",
      "        [3.8457e-01, 7.2020e-01, 1.1124e-01, 9.1535e-01],\n",
      "        [9.7630e-02, 3.3602e-01, 6.9767e-01, 2.0946e-01]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([3,9,6])\n",
    "a = torch.rand(3,4)\n",
    "print(a, b)\n",
    "sorted, idx = torch.sort(b)\n",
    "print(idx)\n",
    "a = a[idx]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cffba8bb1d9d6899bb3471151a356098405dc785e2f3817d0741727c140b6f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
